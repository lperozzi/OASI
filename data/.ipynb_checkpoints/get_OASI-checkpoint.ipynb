{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-05 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 5.1.0\n",
      "\n",
      "pandas 0.18.1\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)\n",
      "system     : Darwin\n",
      "release    : 16.5.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -d -v -m -p pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab data from OASI web database\n",
    "\n",
    "The [OASI web database](http://www.ti.ch/oasi) is an observatory platform for the environmental data (Osservatorio Ambientale della Svizzera Italiana). This database stores data from air quality to meteo, energy, noise, traffic and so on.\n",
    "Each data is accessible by a location (a measure point) and a parameter, dovoded in yearly, monthly, daily and hourly measurment. The limit consist that each database (csv file) is for an unique location and a unique parameter. For example, if we want to get data for PM10, PM2.5, O2, NO3 for Lugano, annualy, we have to download 4 different files. Furthermore, ther is a limit that prevents to download more than 20 days of hourly datas and more than 1 year of daily data. \n",
    "\n",
    "The following code allow to concatenate all the parameter for all location for each resolution (day, month or year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "from_date = \"2007-01-01\"\n",
    "to_date = \"2017-04-30\"\n",
    "\n",
    "parameter = ['pm10','pm2.5','o3','no2']\n",
    "\n",
    "# Airolo, Biasca, Bioggio, Bodio, Brione s. Minusio, Camignolo, Chiasso, Giubiasco, Locarno, Lugano, Magadino, Mendrisio, Pregassona, San Vittore, Vezia\n",
    "location = ['auto_275', '511%2002%2008', '304%2001%2005', '406%2001%2003', '525%2001%2001', '610%2002%2006',\n",
    "           'auto_51', '423%2002%2002', 'Nabel_LUG', 'Nabel_MAG', '614%2001%2003', '596%2001%2001', 'auto_75', '591%2001%2001']\n",
    "city = ['Airolo', 'Bioggio', 'Bodio', 'Bione s. Minusio', 'Camignolo', \n",
    "        'Chiasso', 'Giubiasco', 'Locarno', 'Lugano', 'Magadino', 'Mendrisio',\n",
    "        'Pregassona', 'San Vittore', 'Vezia']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dati giornalieri\n",
    "\n",
    "For daily data, the start date has been fixed to 2009 since auto_51 (Giubiasco) has measurments from 1.10.2008. auto_275 (Airolo) station has been dropped from de location list since it has only measurments starting from 2016. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from_date_d = \"2009-01-01\"\n",
    "to_date_d = \"2017-04-30\"\n",
    "\n",
    "from_index = pd.date_range(from_date_d , to_date_d , freq=\"AS\")\n",
    "to_index = pd.date_range(from_date_d , to_date_d , freq=\"A\")\n",
    "\n",
    "df_from = pd.DataFrame({\"From\": from_index})\n",
    "from_data_d = pd.to_datetime(df_from['From']).dt.strftime('%Y-%m-%d').tolist()\n",
    "df_to = pd.DataFrame({\"To\": to_index})\n",
    "to_data_d = pd.to_datetime(df_to['To']).dt.strftime('%Y-%m-%d').tolist()\n",
    "\n",
    "location = ['511%2002%2008', '304%2001%2005', '406%2001%2003', '525%2001%2001', '610%2002%2006',\n",
    "           'auto_51', '423%2002%2002', 'Nabel_LUG', 'Nabel_MAG', '614%2001%2003', '596%2001%2001', 'auto_75', '591%2001%2001']\n",
    "city = ['Bioggio', 'Bodio', 'Bione s. Minusio', 'Camignolo', \n",
    "        'Chiasso', 'Giubiasco', 'Locarno', 'Lugano', 'Magadino', 'Mendrisio',\n",
    "        'Pregassona', 'San Vittore', 'Vezia']\n",
    "\n",
    "\n",
    "resolution = 'd' # daily resolution\n",
    "urls = []\n",
    "dfs = []\n",
    "# Base URL\n",
    "CSV_URL = 'http://www.oasi.ti.ch/web/rest/measure/csv?domain=air&resolution={}&parameter={}&from={}&to={}&location={}'\n",
    "# from_date = '2016-04-30'\n",
    "# to_date = '2017-04-30'\n",
    "\n",
    "for l in location:\n",
    "    dfs1 = []\n",
    "    for p in parameter:\n",
    "        dfs2 = []\n",
    "        for fd, td in zip(from_data_d, to_data_d):\n",
    "            url = CSV_URL.format(resolution, p, fd, td, l)\n",
    "#             print(url)\n",
    "            df = pd.read_csv(url, comment='#', sep=';', usecols=[0, 1], index_col='data')\n",
    "            dfs2.append(df)\n",
    "        dfs1.append(pd.concat(dfs2, axis=0))\n",
    "    dfs.append(pd.concat(dfs1, axis=1))\n",
    "\n",
    "air_day = pd.concat(dfs, keys=city).rename_axis(('city','data')).reset_index()\n",
    "# .dropna(axis=1, how='all')\n",
    "air_day.to_csv('air_day.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dati mensili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 'm' # risoluzione mensile\n",
    "urls = []\n",
    "dfs = []\n",
    "CSV_URL = 'http://www.oasi.ti.ch/web/rest/measure/csv?domain=air&resolution={}&parameter={}&from={}&to={}&location={}'\n",
    "\n",
    "\n",
    "for l in location:\n",
    "    dfs1 = []\n",
    "    for p in parameter:\n",
    "        url = CSV_URL.format(resolution, p, from_date, to_date, l)\n",
    "        df = pd.read_csv(url, comment='#', sep=';', usecols=[0, 1], index_col='data')\n",
    "        dfs1.append(df)\n",
    "    dfs.append(pd.concat(dfs1, axis=1))\n",
    "\n",
    "air_month = pd.concat(dfs, keys=city).rename_axis(('city','data')).reset_index()\n",
    "# .dropna(axis=1, how='all')\n",
    "air_month.to_csv('air_month.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dati annuali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 'y' # risoluzione mensile\n",
    "urls = []\n",
    "dfs = []\n",
    "CSV_URL = 'http://www.oasi.ti.ch/web/rest/measure/csv?domain=air&resolution={}&parameter={}&from={}&to={}&location={}'\n",
    "\n",
    "\n",
    "for l in location:\n",
    "    dfs1 = []\n",
    "    for p in parameter:\n",
    "        url = CSV_URL.format(resolution, p, from_date, to_date, l)\n",
    "        df = pd.read_csv(url, comment='#', sep=';', usecols=[0, 1], index_col='data')\n",
    "        dfs1.append(df)\n",
    "    dfs.append(pd.concat(dfs1, axis=1))\n",
    "\n",
    "air_year = pd.concat(dfs, keys=city).rename_axis(('city','data')).reset_index()\n",
    "# .dropna(axis=1, how='all')\n",
    "air_year.to_csv('air_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
